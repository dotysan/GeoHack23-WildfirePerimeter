{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# GeoHack 2023 Automated Fire Perimiter\n",
    "#\n",
    "#Provides functions to:\n",
    "# 1.1 > Classify Raster\n",
    "#     > Raster to Vector\n",
    "#     > ??? Project Vectors ???\n",
    "#     > Aggregate Polygons\n",
    "#     > Split\n",
    "#     > Combine\n",
    "#\n",
    "#Information:\n",
    "#     Automated Fire Perimeter model using classification and\n",
    "#     transformation techniques to rapidly build a fire\n",
    "#     shape file. This model reduces noise and accounts for\n",
    "#     layers of human subjectivity based on industry defined\n",
    "#     threshold. Prectical applications for fire inteligence\n",
    "#     are situational awareness of fire growth in a near \n",
    "#     real time environment. Each succesive update offers \n",
    "#     a POI for AI fire pretiction models from other platforms\n",
    "# \n",
    "# Acknowledgments: GeoHack 2023 Team 1 (\"Names/Country Here\")\n",
    "#       > Info:>>>    \n",
    "# By: Tony Ramos\n",
    "# Date: 03/10/2023\n",
    "#\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import shapely\n",
    "import numpy as np\n",
    "import geopandas\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "\n",
    "work_dir = \"./data/\"\n",
    "image = os.path.join(work_dir, \"LWIR_QuickMosaic_16-bit_9327.tiff\")\n",
    "poly = os.path.join(work_dir, \"HeatPoly.shp\")\n",
    "# work_dir =\"Data\"\n",
    "# MillsFire=\"C:/Users/centr/GeoHack23-WildfirePerimeter/Data/LWIR_QuickMosaic_16-bit_9327.tiff\"\n",
    "OutputFilePath =\"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the raster file using rasterio\n",
    "KneeThresh = 33332\n",
    "with rasterio.open(image) as src:\n",
    "    # Read the raster data and metadata\n",
    "    raster_data = src.read(1)  # Read the first band of the raster\n",
    "    raster_meta = src.meta\n",
    "\n",
    "    # Classify the raster data\n",
    "    classified_data = np.where(raster_data < KneeThresh, 0, 1)\n",
    "\n",
    "# Update the metadata with the new data type and nodata value\n",
    "raster_meta.update(dtype=rasterio.uint8, nodata=None)\n",
    "\n",
    "# Write the classified raster to a new file\n",
    "with rasterio.open(OutputFilePath + 'RasterClass.tif', 'w', **raster_meta) as dst:\n",
    "    dst.write(classified_data.astype(rasterio.uint16), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import features\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the raster file using rasterio\n",
    "with rasterio.open(image) as src:\n",
    "    # Read the raster data and metadata\n",
    "    raster_data = src.read(1)  # Read the first band of the raster\n",
    "    raster_meta = src.meta\n",
    "\n",
    "    # Classify the raster data\n",
    "    classified_data = np.where(raster_data < KneeThresh, 0, 1)\n",
    "\n",
    "# Update the metadata with the new data type and nodata value\n",
    "raster_meta.update(dtype=rasterio.int16, nodata=None)\n",
    "\n",
    "# Write the classified raster to a new file\n",
    "with rasterio.open(OutputFilePath + 'RasterClass.tif', 'w', **raster_meta) as dst:\n",
    "    dst.write(classified_data, 1)\n",
    "\n",
    "# Convert the classified raster to polygons\n",
    "shapes = features.shapes(classified_data, transform=raster_meta['transform'])\n",
    "\n",
    "# Write the polygons to a shapefile\n",
    "with fiona.open(OutputFilePath + 'HeatPoly.shp', 'w', 'ESRI Shapefile',crs=fiona.crs.from_epsg(4326), schema={'geometry': 'Polygon', 'properties': {}}) as dst:\n",
    "    for shape in shapes:\n",
    "        value = shape[1]\n",
    "        if value > 0:\n",
    "            feature = {'geometry': shape[0], 'properties': {}}\n",
    "            dst.write(feature)\n",
    "\n",
    "# # (Optional) Display the polygons using matplotlib\n",
    "# with fiona.open(OutputFilePath + 'HeatPoly.shp', 'r') as src:\n",
    "#     for i, layer in enumerate(src):\n",
    "#         if i == 0:\n",
    "#             x, y = [], []\n",
    "#             for poly in layer['geometry']['coordinates']:\n",
    "#                 x += [pt[0] for pt in poly]\n",
    "#                 y += [pt[1] for pt in poly]\n",
    "#             plt.plot(x, y, 'k.')\n",
    "#             plt.axis('equal')\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Define the source and target CRSs\n",
    "src_crs = 'EPSG:4326'  # EPSG:4326 is the default CRS for the input shapefile\n",
    "target_crs = 'EPSG:26910' # New projection NAD 1983 UTM Zone 10N\n",
    "\n",
    "# Read the input shapefile into a GeoDataFrame\n",
    "gdf = gpd.read_file(OutputFilePath + 'HeatPoly.shp', crs=src_crs)\n",
    "\n",
    "# Reproject the GeoDataFrame to the target CRS\n",
    "gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "# Write the reprojected GeoDataFrame to a new shapefile\n",
    "gdf.to_file(OutputFilePath + 'HeatPoly_reprojected.shp', driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as shp\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "# Load your polygons into a GeoDataFrame\n",
    "polygons = shp.read_file(work_dir + 'HeatPoly.shp')\n",
    "\n",
    "# Set the distance within which you want to aggregate polygons\n",
    "distance = 1  # in meters\n",
    "\n",
    "# Create a buffer around each polygon using the distance\n",
    "buffered = polygons.geometry.buffer(distance)\n",
    "\n",
    "# Group buffered polygons that intersect with each other\n",
    "groups = buffered.unary_union\n",
    "\n",
    "# Convert the grouped polygons back to a GeoDataFrame\n",
    "if isinstance(groups, MultiPolygon):\n",
    "    grouped_polygons = gpd.GeoDataFrame(\n",
    "        {'geometry': [polygon for polygon in groups]},\n",
    "        crs=polygons.crs\n",
    "    )\n",
    "else:\n",
    "    grouped_polygons = gpd.GeoDataFrame(\n",
    "        {'geometry': [groups]},\n",
    "        crs=polygons.crs\n",
    "    )\n",
    "\n",
    "# Save the aggregated polygons to a shapefile\n",
    "grouped_polygons.to_file(OutputFilePath + 'Aggrigate.shp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildfire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
